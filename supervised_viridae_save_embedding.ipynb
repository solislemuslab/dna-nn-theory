{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supervised_viridae_save embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMugZ5eke2ixxK3hpGSZtl8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/supervised_viridae_save_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSO3GWw8FWG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuvNh5Ia8vvD"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SYc4iv-RPC",
        "outputId": "b5ca120f-753f-4d7d-9769-f7a2b3847ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTavNzohPEjl",
        "outputId": "db40ea6a-2767-4a99-fcd9-46027cf744b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data_path = '/content/gdrive/My Drive/Colab Notebooks/viridae/'\n",
        "records_df = pd.read_csv(data_path + 'clean.csv')\n",
        "# replace all '-' with N (stands for any nt)\n",
        "records_df.seq = records_df.seq.str.replace('-', 'N')\n",
        "records_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>seq</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NC_036588.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NC_014412.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NC_014413.1</td>\n",
              "      <td>GNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NC_025890.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NC_023162.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                                seq  label\n",
              "0  NC_036588.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "1  NC_014412.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "2  NC_014413.1  GNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "3  NC_025890.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "4  NC_023162.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IFMicpqYIl",
        "outputId": "48536649-7f33-49d4-d813-02daa04cf45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "seq_num = 0\n",
        "for seq in records_df[\"seq\"]:\n",
        "  char_num = 0\n",
        "  for char in seq:\n",
        "    if char != 'A' and char != 'C' and char != 'T' and char != 'G' and char != 'N':\n",
        "      print(\"seq\", seq_num, 'char', char_num, 'is', char)\n",
        "    char_num += 1\n",
        "  seq_num += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seq 67 char 3290 is R\n",
            "seq 67 char 3858 is R\n",
            "seq 82 char 1766 is Y\n",
            "seq 241 char 2298 is R\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myCtGYFV37Re"
      },
      "source": [
        "records_df.seq = records_df.seq.str.replace('R', 'N')\n",
        "records_df.seq = records_df.seq.str.replace('Y', 'N')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFFjXSJP88L",
        "outputId": "c6ee11e9-0474-41d6-c644-c921ac982d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# check if the length of the sequence is the same \n",
        "seq_len = len(records_df.seq[0])\n",
        "print(\"The length of the sequence is\", seq_len)\n",
        "for seq in records_df.seq[:200]:\n",
        "  assert len(seq) == seq_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the sequence is 4132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUWH2qMJ4MlM"
      },
      "source": [
        "# records_df[\"unigram\"] = records_df.seq.str.replace('', ' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHtYnLfkcrz",
        "outputId": "52ba0bf9-bd64-4188-ac46-d4dc11427cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "xtrain_full, xtest, ytrain_full, ytest = train_test_split(records_df, records_df.label, test_size=0.2, random_state=100, stratify=records_df.label)\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrain_full, ytrain_full, test_size=0.2, random_state=100, stratify=ytrain_full)\n",
        "print(\"shape of training, validation, test set\\n\", xtrain.shape, xval.shape, xtest.shape, ytrain.shape, yval.shape, ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training, validation, test set\n",
            " (179, 3) (45, 3) (57, 3) (179,) (45,) (57,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2h9sGLCVtDn",
        "outputId": "c0f71a74-581f-4d41-8dd1-c1cce3396504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_size = 1\n",
        "vocab = [''.join(p) for p in product('ACGTN', repeat=word_size)]\n",
        "# word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "vocab_size = 5\n",
        "print('vocab_size:', vocab_size)\n",
        "# print(\"word_to_idx\", word_to_idx)\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\n",
        ")\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPvs2BCU_Mk"
      },
      "source": [
        "def ds_preprocess(x, y):\n",
        "  x_index = tf.subtract(create1gram(x), 2)\n",
        "  return x_index, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvsJkEa0YuT",
        "outputId": "cf63b1b7-a01e-4fc1-ec63-360387f9ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# not sure the correct way to get mapping from word to its index\n",
        "create1gram('A C G T N') - 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([4, 3, 2, 0, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzLRmqEjSitl"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "xtrain_ds = tf.data.Dataset.from_tensor_slices((xtrain['seq'], ytrain)).map(ds_preprocess).batch(BATCH_SIZE)\n",
        "xval_ds = tf.data.Dataset.from_tensor_slices((xval['seq'], yval)).map(ds_preprocess).batch(BATCH_SIZE)\n",
        "xtest_ds = tf.data.Dataset.from_tensor_slices((xtest['seq'], ytest)).map(ds_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLaIchQUWQl",
        "outputId": "e892d932-a239-4cd2-930b-6bca978022a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "latent_size = 256\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(seq_len,)),\n",
        "    keras.layers.Embedding(seq_len, latent_size),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),    \n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),  \n",
        "    keras.layers.Dropout(0.2), \n",
        "    keras.layers.Dense(16, activation=\"relu\"), \n",
        "    keras.layers.Dropout(0.2),   \n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")                               \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 4132, 256)         1057792   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,626,881\n",
            "Trainable params: 1,626,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlnaNStWLNK",
        "outputId": "dc9e3e20-8199-4c88-e130-eaed0c099997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.SGD(), loss=tf.losses.BinaryCrossentropy(), metrics='accuracy')\n",
        "es_cb = keras.callbacks.EarlyStopping(patience=400, restore_best_weights=True)\n",
        "hist = model.fit(xtrain_ds, validation_data=xval_ds, epochs=5000, callbacks=[es_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.6931 - accuracy: 0.5140 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
            "Epoch 2/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6930 - accuracy: 0.5196 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
            "Epoch 3/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6935 - accuracy: 0.4581 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
            "Epoch 4/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6936 - accuracy: 0.4749 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
            "Epoch 5/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6931 - accuracy: 0.5196 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
            "Epoch 6/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6925 - accuracy: 0.5698 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
            "Epoch 7/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
            "Epoch 8/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6928 - accuracy: 0.5587 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
            "Epoch 9/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6930 - accuracy: 0.5363 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
            "Epoch 10/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6930 - accuracy: 0.4916 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 11/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 12/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6927 - accuracy: 0.5363 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 13/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6931 - accuracy: 0.4916 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 14/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6934 - accuracy: 0.4860 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 15/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6926 - accuracy: 0.5475 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 16/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6925 - accuracy: 0.5475 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 17/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6930 - accuracy: 0.5196 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 18/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6927 - accuracy: 0.5419 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 19/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6924 - accuracy: 0.5140 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 20/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6927 - accuracy: 0.5363 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 21/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6925 - accuracy: 0.5419 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 22/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 23/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6925 - accuracy: 0.5419 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 24/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 25/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6925 - accuracy: 0.5251 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 26/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6920 - accuracy: 0.5363 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 27/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6923 - accuracy: 0.5475 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 28/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6928 - accuracy: 0.5363 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 29/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6923 - accuracy: 0.5475 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 30/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6927 - accuracy: 0.5363 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 31/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6926 - accuracy: 0.5363 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 32/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 33/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6926 - accuracy: 0.5419 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 34/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6920 - accuracy: 0.5363 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 35/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 36/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 37/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6925 - accuracy: 0.5363 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 38/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 39/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6924 - accuracy: 0.5419 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 40/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 41/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 42/5000\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 43/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 44/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 45/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 46/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 47/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 48/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 49/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 50/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 51/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 52/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 53/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 54/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 55/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 56/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 57/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 58/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 59/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 60/5000\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 61/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 62/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 63/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 64/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 65/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 66/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 67/5000\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 68/5000\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 69/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 70/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 71/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 72/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 73/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 74/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 75/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 76/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 77/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 78/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 79/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 80/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 81/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 82/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 83/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 84/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 85/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 86/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 87/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 88/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 89/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 90/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 91/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 92/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 93/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 94/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 95/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 96/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 97/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 98/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 99/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 100/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 101/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 102/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 103/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 104/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 105/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 106/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 107/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 108/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 109/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 110/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 111/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 112/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 113/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 114/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 115/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 116/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 117/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 118/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 119/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 120/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 121/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 122/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 123/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 124/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 125/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 126/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 127/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 128/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 129/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 130/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 131/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 132/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 133/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 134/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 135/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 136/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 137/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 138/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 139/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 140/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 141/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 142/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 143/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 144/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 145/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 146/5000\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 147/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 148/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 149/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 150/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 151/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 152/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 153/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 154/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 155/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 156/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 157/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 158/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 159/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 160/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 161/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 162/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 163/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 164/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 165/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 166/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 167/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 168/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 169/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 170/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 171/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 172/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 173/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 174/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 175/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 176/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 177/5000\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 178/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 179/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 180/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 181/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 182/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 183/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 184/5000\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 185/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 186/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 187/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 188/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 189/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 190/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 191/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 192/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 193/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 194/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 195/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 196/5000\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 197/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 198/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 199/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 200/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 201/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 202/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 203/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 204/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 205/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 206/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 207/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 208/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 209/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 210/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 211/5000\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 212/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 213/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6880 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 214/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 215/5000\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 216/5000\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 217/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 218/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 219/5000\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 220/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 221/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 222/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 223/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 224/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 225/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 226/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 227/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 228/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 229/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 230/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 231/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 232/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 233/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 234/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 235/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 236/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 237/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 238/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 239/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 240/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 241/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 242/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 243/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 244/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 245/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 246/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 247/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 248/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 249/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 250/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 251/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 252/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 253/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 254/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 255/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 256/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 257/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 258/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 259/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 260/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 261/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 262/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 263/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 264/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 265/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 266/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 267/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 268/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 269/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 270/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 271/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 272/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 273/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 274/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 275/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 276/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 277/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 278/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 279/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 280/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 281/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 282/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 283/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 284/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 285/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 286/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 287/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 288/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 289/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 290/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 291/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 292/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 293/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 294/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 295/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 296/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 297/5000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 298/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 299/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 300/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 301/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 302/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 303/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 304/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 305/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 306/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 307/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 308/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 309/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 310/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 311/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 312/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 313/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 314/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 315/5000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 316/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 317/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 318/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6881 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 319/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 320/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 321/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 322/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 323/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 324/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 325/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 326/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6875 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 327/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 328/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 329/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 330/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 331/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 332/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 333/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 334/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 335/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6937 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 336/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 337/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 338/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 339/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 340/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 341/5000\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 342/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 343/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 344/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 345/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 346/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 347/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 348/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 349/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 350/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 351/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 352/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 353/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 354/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 355/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 356/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 357/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 358/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 359/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 360/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 361/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 362/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 363/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 364/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 365/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 366/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 367/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 368/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 369/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 370/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 371/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 372/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 373/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 374/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 375/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 376/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 377/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 378/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 379/5000\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 380/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 381/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 382/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 383/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 384/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 385/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 386/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 387/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 388/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 389/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 390/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 391/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 392/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6878 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 393/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6880 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 394/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 395/5000\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 396/5000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 397/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 398/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 399/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 400/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6878 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 401/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 402/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 403/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 404/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 405/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 406/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 407/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 408/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 409/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 410/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 411/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 412/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 413/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 414/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 415/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 416/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 417/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 418/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 419/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 420/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 421/5000\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 422/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 423/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 424/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 425/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 426/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 427/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 428/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 429/5000\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 430/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 431/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 432/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 433/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 434/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 435/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 436/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 437/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 438/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 439/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 440/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 441/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 442/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 443/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 444/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 445/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 446/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 447/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 448/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 449/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 450/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 451/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 452/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 453/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 454/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 455/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 456/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 457/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 458/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6868 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 459/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 460/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 461/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 462/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 463/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 464/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 465/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 466/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 467/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 468/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 469/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 470/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 471/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 472/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 473/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 474/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 475/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 476/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 477/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 478/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 479/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 480/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 481/5000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 482/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6874 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 483/5000\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 484/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 485/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6880 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 486/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 487/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 488/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 489/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 490/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 491/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 492/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 493/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 494/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 495/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 496/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 497/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 498/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 499/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 500/5000\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.6876 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 501/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 502/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 503/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 504/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 505/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 506/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 507/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6881 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 508/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 509/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 510/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 511/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 512/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 513/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 514/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6881 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 515/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 516/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 517/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 518/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 519/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 520/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 521/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 522/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 523/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 524/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 525/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 526/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 527/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 528/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 529/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 530/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 531/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 532/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 533/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 534/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 535/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 536/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 537/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 538/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 539/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 540/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 541/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 542/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 543/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 544/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 545/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 546/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 547/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 548/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 549/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 550/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 551/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 552/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 553/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 554/5000\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 555/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 556/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 557/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 558/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 559/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 560/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 561/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 562/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 563/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 564/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 565/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 566/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 567/5000\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 568/5000\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 569/5000\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 570/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 571/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 572/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 573/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 574/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 575/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 576/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 577/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 578/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 579/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 580/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 581/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 582/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 583/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 584/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 585/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 586/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 587/5000\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 588/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 589/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 590/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 591/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 592/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 593/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 594/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 595/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 596/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 597/5000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 598/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 599/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 600/5000\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 601/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 602/5000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 603/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 604/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 605/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 606/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 607/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 608/5000\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 609/5000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 610/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 611/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6880 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 612/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 613/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 614/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 615/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 616/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 617/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 618/5000\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.6872 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 619/5000\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 620/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 621/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 622/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 623/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 624/5000\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 625/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 626/5000\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 627/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 628/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 629/5000\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.6874 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 630/5000\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 631/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 632/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 633/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 634/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 635/5000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 636/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 637/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 638/5000\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 639/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 640/5000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 641/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 642/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 643/5000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 644/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 645/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 646/5000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 647/5000\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6878 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 648/5000\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 649/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 650/5000\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 651/5000\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NRw0R65wVq9"
      },
      "source": [
        "\n",
        "def save_hist():\n",
        "  filename = data_path + \"baseline_viridae_sgd256_history.csv\"\n",
        "  hist_df = pd.DataFrame(hist.history) \n",
        "  with open(filename, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "save_hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC15X36ywjTF"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Colab Notebooks/models/' + \"baseline_viridae_sgd256.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiRiXQHwNOS",
        "outputId": "03dc2ed1-3f47-46d4-89d0-31d205f2daca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(hist.history['loss'], label='training')\n",
        "  ax1.plot(hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('lstm autoencoder loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(hist.history['accuracy'], label='training')\n",
        "  ax2.plot(hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('lstm autoencoder accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sgxZ6qrU9-9"
      },
      "source": [
        "def eval_model(model, ds, ds_name=\"Training\"):\n",
        "  loss, acc = model.evaluate(ds, verbose=0)\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}%\".format(ds_name, np.round(loss, 3), np.round(acc*100, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcedsFqDUnm",
        "outputId": "c0ccecde-3553-4dea-9971-1743cc967d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "eval_model(model, xtrain_ds, \"Training\")\n",
        "eval_model(model, xval_ds, \"Validation\")\n",
        "eval_model(model, xtest_ds, \"Test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.69 and acccuracy = 54.19%\n",
            "Validation Dataset: loss = 0.691 and acccuracy = 53.33%\n",
            "Test Dataset: loss = 0.689 and acccuracy = 54.39%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}