{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of supervised_viridae_sgd256_save embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYfx9CpdyhNGUtVuwV9MMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/Copy_of_supervised_viridae_sgd256_save_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSO3GWw8FWG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuvNh5Ia8vvD"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SYc4iv-RPC",
        "outputId": "24c81476-9e18-4375-e5cb-86bb1f6fc81e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.2)\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTavNzohPEjl",
        "outputId": "0f13009f-429b-4cdb-ab55-86b821ddae21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data_path = '/content/gdrive/My Drive/Colab Notebooks/viridae/'\n",
        "records_df = pd.read_csv(data_path + 'clean.csv')\n",
        "# replace all '-' with N (stands for any nt)\n",
        "records_df.seq = records_df.seq.str.replace('-', 'N')\n",
        "records_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>seq</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NC_036588.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NC_014412.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NC_014413.1</td>\n",
              "      <td>GNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NC_025890.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NC_023162.1</td>\n",
              "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                                seq  label\n",
              "0  NC_036588.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "1  NC_014412.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "2  NC_014413.1  GNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "3  NC_025890.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0\n",
              "4  NC_023162.1  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IFMicpqYIl",
        "outputId": "83f70f36-1ae5-4f56-8da5-26d189d54c61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seq_num = 0\n",
        "for seq in records_df[\"seq\"]:\n",
        "  char_num = 0\n",
        "  for char in seq:\n",
        "    if char != 'A' and char != 'C' and char != 'T' and char != 'G' and char != 'N':\n",
        "      print(\"seq\", seq_num, 'char', char_num, 'is', char)\n",
        "    char_num += 1\n",
        "  seq_num += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seq 67 char 3290 is R\n",
            "seq 67 char 3858 is R\n",
            "seq 82 char 1766 is Y\n",
            "seq 241 char 2298 is R\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myCtGYFV37Re"
      },
      "source": [
        "records_df.seq = records_df.seq.str.replace('R', 'N')\n",
        "records_df.seq = records_df.seq.str.replace('Y', 'N')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFFjXSJP88L",
        "outputId": "255a2f37-53c5-4476-ba8f-834f823e6002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# extract only last 2449 nts\n",
        "length = 2449\n",
        "records_df.seq = records_df.seq.str[-length:]\n",
        "seq_len = len(records_df.seq[0])\n",
        "print(\"The length of the sequence is\", seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the sequence is 2449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUWH2qMJ4MlM"
      },
      "source": [
        "# records_df[\"unigram\"] = records_df.seq.str.replace('', ' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHtYnLfkcrz",
        "outputId": "af70f8cf-f6f5-443d-f259-2e26ee75c172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "xtrain_full, xtest, ytrain_full, ytest = train_test_split(records_df, records_df.label, test_size=0.2, random_state=100, stratify=records_df.label)\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrain_full, ytrain_full, test_size=0.2, random_state=100, stratify=ytrain_full)\n",
        "print(\"shape of training, validation, test set\\n\", xtrain.shape, xval.shape, xtest.shape, ytrain.shape, yval.shape, ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training, validation, test set\n",
            " (179, 3) (45, 3) (57, 3) (179,) (45,) (57,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2h9sGLCVtDn",
        "outputId": "d04ffc6d-32a2-49da-d4d8-98ffdbf6603d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_size = 1\n",
        "vocab = [''.join(p) for p in product('ACGTN', repeat=word_size)]\n",
        "# word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "vocab_size = 5\n",
        "print('vocab_size:', vocab_size)\n",
        "# print(\"word_to_idx\", word_to_idx)\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\n",
        ")\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPvs2BCU_Mk"
      },
      "source": [
        "def ds_preprocess(x, y):\n",
        "  x_index = tf.subtract(create1gram(x), 2)\n",
        "  return x_index, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvsJkEa0YuT",
        "outputId": "cf63b1b7-a01e-4fc1-ec63-360387f9ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# not sure the correct way to get mapping from word to its index\n",
        "create1gram('A C G T N') - 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([4, 3, 2, 0, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzLRmqEjSitl"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "xtrain_ds = tf.data.Dataset.from_tensor_slices((xtrain['seq'], ytrain)).map(ds_preprocess).batch(BATCH_SIZE)\n",
        "xval_ds = tf.data.Dataset.from_tensor_slices((xval['seq'], yval)).map(ds_preprocess).batch(BATCH_SIZE)\n",
        "xtest_ds = tf.data.Dataset.from_tensor_slices((xtest['seq'], ytest)).map(ds_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLaIchQUWQl",
        "outputId": "ac5689ac-cc67-4fbe-d9df-685ef6965f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "latent_size = 256\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(seq_len,)),\n",
        "    keras.layers.Embedding(seq_len, latent_size),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),    \n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),  \n",
        "    keras.layers.Dropout(0.2), \n",
        "    keras.layers.Dense(16, activation=\"relu\"), \n",
        "    keras.layers.Dropout(0.2),   \n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")                               \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 2449, 256)         626944    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,196,033\n",
            "Trainable params: 1,196,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlnaNStWLNK",
        "outputId": "60fb5035-69da-4fc1-84c1-68a5130eef7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.SGD(), loss=tf.losses.BinaryCrossentropy(), metrics='accuracy')\n",
        "es_cb = keras.callbacks.EarlyStopping(patience=400, restore_best_weights=True)\n",
        "hist = model.fit(xtrain_ds, validation_data=xval_ds, epochs=5000, callbacks=[es_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 0.6938 - accuracy: 0.4190 - val_loss: 0.6933 - val_accuracy: 0.4667\n",
            "Epoch 2/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6936 - accuracy: 0.4413 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
            "Epoch 3/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6937 - accuracy: 0.4916 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
            "Epoch 4/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6931 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.4667\n",
            "Epoch 5/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6931 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
            "Epoch 6/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6921 - accuracy: 0.6089 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
            "Epoch 7/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6927 - accuracy: 0.5307 - val_loss: 0.6931 - val_accuracy: 0.5333\n",
            "Epoch 8/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6936 - accuracy: 0.4749 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
            "Epoch 9/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6932 - accuracy: 0.5363 - val_loss: 0.6930 - val_accuracy: 0.5333\n",
            "Epoch 10/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6930 - accuracy: 0.5251 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 11/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6940 - accuracy: 0.4413 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 12/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6933 - accuracy: 0.4693 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 13/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6931 - accuracy: 0.4637 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 14/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6932 - accuracy: 0.4525 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 15/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 16/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6930 - accuracy: 0.5363 - val_loss: 0.6928 - val_accuracy: 0.5333\n",
            "Epoch 17/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6928 - accuracy: 0.5251 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 18/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6931 - accuracy: 0.4693 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 19/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6928 - accuracy: 0.5307 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 20/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 21/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 22/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6928 - accuracy: 0.5307 - val_loss: 0.6927 - val_accuracy: 0.5333\n",
            "Epoch 23/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6930 - accuracy: 0.5475 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 24/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6927 - accuracy: 0.5251 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 25/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6925 - accuracy: 0.5531 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 26/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6924 - accuracy: 0.5419 - val_loss: 0.6926 - val_accuracy: 0.5333\n",
            "Epoch 27/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6926 - accuracy: 0.5419 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 28/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6930 - accuracy: 0.5307 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 29/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6927 - accuracy: 0.5475 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 30/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6930 - accuracy: 0.5251 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 31/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6929 - accuracy: 0.5531 - val_loss: 0.6925 - val_accuracy: 0.5333\n",
            "Epoch 32/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6928 - accuracy: 0.5251 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 33/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6930 - accuracy: 0.5419 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 34/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6927 - accuracy: 0.5251 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 35/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6924 - accuracy: 0.5307 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 36/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6925 - accuracy: 0.5363 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 37/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6926 - accuracy: 0.5475 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 38/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6923 - accuracy: 0.5475 - val_loss: 0.6924 - val_accuracy: 0.5333\n",
            "Epoch 39/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6917 - accuracy: 0.5307 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 40/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6927 - accuracy: 0.5196 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 41/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6926 - accuracy: 0.5307 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 42/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6918 - accuracy: 0.5307 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 43/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6925 - accuracy: 0.5307 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 44/5000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.6922 - accuracy: 0.5307 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 45/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6919 - accuracy: 0.5363 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 46/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6923 - accuracy: 0.5363 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 47/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6925 - accuracy: 0.5363 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 48/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 49/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6921 - accuracy: 0.5251 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 50/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 51/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6927 - accuracy: 0.5363 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 52/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 53/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6924 - accuracy: 0.5419 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 54/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6929 - accuracy: 0.5363 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 55/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6922 - accuracy: 0.5363 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 56/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6922 - accuracy: 0.5363 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 57/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 58/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6921 - accuracy: 0.5307 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 59/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6921 - accuracy: 0.5363 - val_loss: 0.6921 - val_accuracy: 0.5333\n",
            "Epoch 60/5000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 61/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 62/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 63/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6915 - accuracy: 0.5475 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 64/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 65/5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.6919 - accuracy: 0.5363 - val_loss: 0.6920 - val_accuracy: 0.5333\n",
            "Epoch 66/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6921 - accuracy: 0.5363 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 67/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 68/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6916 - accuracy: 0.5475 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 69/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 70/5000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 71/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 72/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 73/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
            "Epoch 74/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 75/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 76/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 77/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 78/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 79/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 80/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 81/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 82/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 83/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 84/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 85/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6920 - accuracy: 0.5363 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 86/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 87/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 88/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 89/5000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 90/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 91/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 92/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 93/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 94/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 95/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 96/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 97/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6917 - val_accuracy: 0.5333\n",
            "Epoch 98/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 99/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 100/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 101/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6923 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 102/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 103/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 104/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 105/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 106/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 107/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 108/5000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 109/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 110/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
            "Epoch 111/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 112/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 113/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 114/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 115/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 116/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 117/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 118/5000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 119/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 120/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 121/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 122/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
            "Epoch 123/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 124/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 125/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 126/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 127/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 128/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 129/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 130/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 131/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 132/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 133/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 134/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 135/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 136/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
            "Epoch 137/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 138/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 139/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 140/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 141/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 142/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 143/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 144/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 145/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 146/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 147/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 148/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 149/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 150/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 151/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 152/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 153/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 154/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 155/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 156/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 157/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 158/5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 159/5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6913 - val_accuracy: 0.5333\n",
            "Epoch 160/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 161/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 162/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 163/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 164/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 165/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 166/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 167/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6924 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 168/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 169/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 170/5000\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 171/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 172/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 173/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 174/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 175/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 176/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 177/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 178/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 179/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 180/5000\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 181/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 182/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 183/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 184/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 185/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6918 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 186/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 187/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 188/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 189/5000\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 190/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 191/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 192/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 193/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 194/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 195/5000\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 196/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 197/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 198/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 199/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 200/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 201/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 202/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 203/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 204/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 205/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 206/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 207/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 208/5000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 209/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 210/5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 211/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 212/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 213/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 214/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 215/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 216/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 217/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 218/5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 219/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 220/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 221/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 222/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 223/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6911 - val_accuracy: 0.5333\n",
            "Epoch 224/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 225/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 226/5000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 227/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 228/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 229/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 230/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 231/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 232/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 233/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 234/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 235/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 236/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 237/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 238/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 239/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 240/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 241/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 242/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 243/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 244/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 245/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 246/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 247/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 248/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 249/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 250/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 251/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 252/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 253/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 254/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 255/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 256/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 257/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 258/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 259/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 260/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 261/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 262/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 263/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 264/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 265/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 266/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 267/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 268/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 269/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 270/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 271/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 272/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 273/5000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 274/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 275/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 276/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 277/5000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 278/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 279/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 280/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 281/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 282/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 283/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 284/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 285/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 286/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 287/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 288/5000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 289/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 290/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 291/5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 292/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 293/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 294/5000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 295/5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 296/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 297/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 298/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 299/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 300/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 301/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 302/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 303/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 304/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 305/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 306/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 307/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 308/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 309/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 310/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 311/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 312/5000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 313/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 314/5000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 315/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 316/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 317/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 318/5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 319/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 320/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 321/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 322/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 323/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 324/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 325/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 326/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 327/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 328/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 329/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 330/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 331/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 332/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 333/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 334/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 335/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 336/5000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 337/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 338/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 339/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 340/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 341/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 342/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 343/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 344/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6874 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 345/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 346/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 347/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 348/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 349/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 350/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 351/5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 352/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 353/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 354/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 355/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 356/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 357/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 358/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 359/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 360/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 361/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 362/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 363/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 364/5000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 365/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 366/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 367/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 368/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 369/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 370/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 371/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 372/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 373/5000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 374/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 375/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 376/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 377/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 378/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 379/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 380/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 381/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 382/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 383/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 384/5000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 385/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 386/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 387/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 388/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 389/5000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 390/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 391/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 392/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 393/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 394/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 395/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 396/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 397/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 398/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 399/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 400/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 401/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 402/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 403/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 404/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 405/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 406/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 407/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 408/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 409/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 410/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 411/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 412/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 413/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 414/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 415/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 416/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 417/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 418/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 419/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 420/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 421/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 422/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 423/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 424/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 425/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 426/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 427/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 428/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 429/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 430/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 431/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 432/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6881 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 433/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 434/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 435/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 436/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 437/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 438/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 439/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 440/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 441/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 442/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 443/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 444/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 445/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 446/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 447/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 448/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 449/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6919 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 450/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 451/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 452/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 453/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 454/5000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 455/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 456/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 457/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 458/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 459/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 460/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 461/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 462/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 463/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 464/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 465/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 466/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 467/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 468/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6873 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 469/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 470/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 471/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 472/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 473/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 474/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 475/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 476/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 477/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 478/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 479/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 480/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 481/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 482/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 483/5000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 484/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 485/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 486/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 487/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 488/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 489/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 490/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 491/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 492/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 493/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 494/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 495/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 496/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 497/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
            "Epoch 498/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 499/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 500/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 501/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 502/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 503/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 504/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 505/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 506/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 507/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6874 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 508/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 509/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 510/5000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 511/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6878 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 512/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 513/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 514/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 515/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 516/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 517/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 518/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 519/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 520/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 521/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 522/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 523/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 524/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 525/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 526/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 527/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 528/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 529/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 530/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 531/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 532/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 533/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 534/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 535/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 536/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 537/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 538/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 539/5000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 540/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 541/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 542/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 543/5000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 544/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 545/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 546/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 547/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 548/5000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 549/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6878 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 550/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 551/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 552/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 553/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 554/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 555/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 556/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 557/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 558/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 559/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 560/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 561/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 562/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 563/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 564/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 565/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 566/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 567/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6880 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 568/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 569/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 570/5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 571/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 572/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 573/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 574/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 575/5000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 576/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 577/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 578/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 579/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6914 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 580/5000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 581/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 582/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 583/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 584/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 585/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 586/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 587/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 588/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 589/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 590/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 591/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 592/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 593/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 594/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 595/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 596/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 597/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 598/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 599/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 600/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 601/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 602/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 603/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 604/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 605/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 606/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 607/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6915 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 608/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 609/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 610/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6880 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 611/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 612/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 613/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 614/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 615/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 616/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 617/5000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 618/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 619/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6877 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 620/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 621/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 622/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 623/5000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 624/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 625/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6894 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 626/5000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 627/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 628/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 629/5000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 630/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 631/5000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 632/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 633/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 634/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 635/5000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 636/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 637/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 638/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 639/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 640/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 641/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6874 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 642/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 643/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 644/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 645/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 646/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 647/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6881 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 648/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6913 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 649/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 650/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 651/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 652/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 653/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 654/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 655/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 656/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 657/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 658/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 659/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6921 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 660/5000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 661/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 662/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 663/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 664/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 665/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 666/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 667/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 668/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 669/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 670/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 671/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6908 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 672/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 673/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 674/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 675/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 676/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 677/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 678/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 679/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 680/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 681/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 682/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 683/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 684/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 685/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 686/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6911 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 687/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 688/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 689/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 690/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6907 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 691/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 692/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 693/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 694/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 695/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 696/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 697/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 698/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 699/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 700/5000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 701/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 702/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 703/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 704/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 705/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 706/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 707/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 708/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6906 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 709/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6890 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 710/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 711/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 712/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 713/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 714/5000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6916 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 715/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 716/5000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6886 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 717/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 718/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 719/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 720/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 721/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 722/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 723/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 724/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6888 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 725/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6885 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 726/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 727/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 728/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 729/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6883 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 730/5000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 731/5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 732/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 733/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 734/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 735/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 736/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 737/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 738/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6909 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 739/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 740/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 741/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6882 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 742/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 743/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6879 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 744/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6905 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 745/5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 746/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 747/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 748/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 749/5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6917 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 750/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 751/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 752/5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 753/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6878 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 754/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6869 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 755/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 756/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6912 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 757/5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6910 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 758/5000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 759/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 760/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6898 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 761/5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6900 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 762/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6899 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 763/5000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6884 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 764/5000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6901 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 765/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6920 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 766/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.6904 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 767/5000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 768/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 769/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6892 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 770/5000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6875 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 771/5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 772/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6887 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 773/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6897 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 774/5000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.6895 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 775/5000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6893 - accuracy: 0.5419 - val_loss: 0.6910 - val_accuracy: 0.5333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NRw0R65wVq9"
      },
      "source": [
        "\n",
        "def save_hist():\n",
        "  filename = data_path + \"baseline_viridae(rear)_sgd256_history.csv\"\n",
        "  hist_df = pd.DataFrame(hist.history) \n",
        "  with open(filename, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "save_hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC15X36ywjTF"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Colab Notebooks/models/' + \"baseline_viridae(rear)_sgd256.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiRiXQHwNOS",
        "outputId": "3f11cc3b-9792-4673-bc8f-0e7b2455c2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(hist.history['loss'], label='training')\n",
        "  ax1.plot(hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('lstm autoencoder loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(hist.history['accuracy'], label='training')\n",
        "  ax2.plot(hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('lstm autoencoder accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sgxZ6qrU9-9"
      },
      "source": [
        "def eval_model(model, ds, ds_name=\"Training\"):\n",
        "  loss, acc = model.evaluate(ds, verbose=0)\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}%\".format(ds_name, np.round(loss, 3), np.round(acc*100, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcedsFqDUnm",
        "outputId": "1df3c605-4e25-47f4-944c-c97f4d6986be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval_model(model, xtrain_ds, \"Training\")\n",
        "eval_model(model, xval_ds, \"Validation\")\n",
        "eval_model(model, xtest_ds, \"Test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.69 and acccuracy = 54.19%\n",
            "Validation Dataset: loss = 0.691 and acccuracy = 53.33%\n",
            "Test Dataset: loss = 0.689 and acccuracy = 54.39%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
